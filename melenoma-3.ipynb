{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e454e10e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:24:37.747020Z",
     "iopub.status.busy": "2025-08-13T12:24:37.746794Z",
     "iopub.status.idle": "2025-08-13T12:24:53.351047Z",
     "shell.execute_reply": "2025-08-13T12:24:53.350252Z"
    },
    "id": "-BdpKXDGmk2Z",
    "outputId": "d554f966-6daf-483a-8b64-28a3d6b97ee6",
    "papermill": {
     "duration": 15.608897,
     "end_time": "2025-08-13T12:24:53.352573",
     "exception": false,
     "start_time": "2025-08-13T12:24:37.743676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 12:24:40.776949: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755087880.986212      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755087881.047768      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, Concatenate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import kagglehub\n",
    "from tensorflow.keras.optimizers import Adam  # <-- import here\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e7db3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:24:53.357754Z",
     "iopub.status.busy": "2025-08-13T12:24:53.357348Z",
     "iopub.status.idle": "2025-08-13T12:24:53.562583Z",
     "shell.execute_reply": "2025-08-13T12:24:53.562037Z"
    },
    "papermill": {
     "duration": 0.208964,
     "end_time": "2025-08-13T12:24:53.563867",
     "exception": false,
     "start_time": "2025-08-13T12:24:53.354903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Download dataset\n",
    "path = kagglehub.dataset_download(\"nroman/melanoma-external-malignant-256\")\n",
    "\n",
    "# Paths\n",
    "train_dir = os.path.join(path, 'train/train')\n",
    "test_dir = os.path.join(path, 'test/test')\n",
    "csv_path = os.path.join(path, 'train_concat.csv')\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "df['image_name'] = df['image_name'].apply(lambda x: x + '.jpg' if not x.endswith('.jpg') else x)\n",
    "df['target'] = df['target'].astype(int)  # keep as int for binary\n",
    "\n",
    "# Features\n",
    "tab_features = ['anatom_site_general_challenge', 'sex', 'age_approx']\n",
    "\n",
    "# Train/val split\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfcaa268",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:24:53.568536Z",
     "iopub.status.busy": "2025-08-13T12:24:53.568336Z",
     "iopub.status.idle": "2025-08-13T12:26:15.768455Z",
     "shell.execute_reply": "2025-08-13T12:26:15.767823Z"
    },
    "papermill": {
     "duration": 82.203728,
     "end_time": "2025-08-13T12:26:15.769657",
     "exception": false,
     "start_time": "2025-08-13T12:24:53.565929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30118 validated image filenames.\n",
      "Found 7530 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Image generators (images only)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, rotation_range=20, width_shift_range=0.2,\n",
    "    height_shift_range=0.2, horizontal_flip=True, fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Image generators (images only) -- keep shuffle=False for alignment\n",
    "train_img_flow = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df.sort_values('image_name'),  # sort to match tabular order\n",
    "    directory=train_dir,\n",
    "    x_col='image_name',\n",
    "    y_col=None,\n",
    "    target_size=(256, 256),\n",
    "    class_mode=None,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "val_img_flow = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df.sort_values('image_name'),\n",
    "    directory=train_dir,\n",
    "    x_col='image_name',\n",
    "    y_col=None,\n",
    "    target_size=(256, 256),\n",
    "    class_mode=None,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "# Combined generator fix\n",
    "def combined_gen(img_gen, tab_data, labels):\n",
    "    tab_data = np.array(tab_data, dtype=np.float32)\n",
    "    labels = np.array(labels, dtype=np.float32)\n",
    "    while True:\n",
    "        for i in range(len(img_gen)):\n",
    "            img_batch = img_gen[i]\n",
    "            start = i * img_gen.batch_size\n",
    "            end = start + img_gen.batch_size\n",
    "            yield (img_batch.astype(np.float32), tab_data[start:end]), labels[start:end]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "918d97e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:26:15.775173Z",
     "iopub.status.busy": "2025-08-13T12:26:15.774600Z",
     "iopub.status.idle": "2025-08-13T12:26:15.909004Z",
     "shell.execute_reply": "2025-08-13T12:26:15.908431Z"
    },
    "papermill": {
     "duration": 0.138289,
     "end_time": "2025-08-13T12:26:15.910270",
     "exception": false,
     "start_time": "2025-08-13T12:26:15.771981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# ----- Process Tabular Data -----\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ]), ['anatom_site_general_challenge', 'sex']),\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), ['age_approx'])\n",
    "    ]\n",
    ")\n",
    "# Also sort tabular data in same order\n",
    "train_df_sorted = train_df.sort_values('image_name')\n",
    "val_df_sorted = val_df.sort_values('image_name')\n",
    "X_train_tab = preprocessor.fit_transform(train_df_sorted[tab_features])\n",
    "X_val_tab = preprocessor.transform(val_df_sorted[tab_features])\n",
    "y_train = train_df_sorted['target'].values\n",
    "y_val = val_df_sorted['target'].values\n",
    "\n",
    "y_train = train_df['target'].values\n",
    "y_val = val_df['target'].values\n",
    "\n",
    "\n",
    "# print(\"NaNs in X_train_tab:\", np.isnan(X_train_tab).any())\n",
    "# print(\"Infs in X_train_tab:\", np.isinf(X_train_tab).any())\n",
    "# print(\"NaNs in y_train:\", np.isnan(y_train).any())\n",
    "# print(\"Infs in y_train:\", np.isinf(y_train).any())\n",
    "# print(\"NaNs in X_val_tab:\", np.isnan(X_val_tab).any())\n",
    "# print(\"Infs in X_val_tab:\", np.isinf(X_val_tab).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37b9e3e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:26:15.915365Z",
     "iopub.status.busy": "2025-08-13T12:26:15.915147Z",
     "iopub.status.idle": "2025-08-13T12:26:18.268836Z",
     "shell.execute_reply": "2025-08-13T12:26:18.268221Z"
    },
    "papermill": {
     "duration": 2.357682,
     "end_time": "2025-08-13T12:26:18.270121",
     "exception": false,
     "start_time": "2025-08-13T12:26:15.912439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755087976.996810      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1755087976.997460      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----- Model -----\n",
    "# CNN for images\n",
    "image_input = Input(shape=(256, 256, 3))\n",
    "x = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "x = MaxPooling2D(2, 2)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(2, 2)(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(2, 2)(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Dense for tabular\n",
    "tab_input = Input(shape=(X_train_tab.shape[1],))\n",
    "t = Dense(32, activation='relu')(tab_input)\n",
    "\n",
    "# Merge\n",
    "merged = Concatenate()([x, t])\n",
    "merged = Dense(512, activation='relu')(merged)\n",
    "merged = Dropout(0.5)(merged)\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model(inputs=[image_input, tab_input], outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),  # lower LR from 0.001 to 0.0001\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "182f9cb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:26:18.275109Z",
     "iopub.status.busy": "2025-08-13T12:26:18.274919Z",
     "iopub.status.idle": "2025-08-13T13:07:33.048747Z",
     "shell.execute_reply": "2025-08-13T13:07:33.048126Z"
    },
    "papermill": {
     "duration": 2474.777935,
     "end_time": "2025-08-13T13:07:33.050272",
     "exception": false,
     "start_time": "2025-08-13T12:26:18.272337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755087982.140889      62 service.cc:148] XLA service 0x79e3f8004000 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1755087982.141673      62 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1755087982.141696      62 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1755087982.592516      62 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  2/942\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 69ms/step - accuracy: 0.8047 - auc: 0.4051 - loss: 2.5132  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755087988.773179      62 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m942/942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 654ms/step - accuracy: 0.8654 - auc: 0.5025 - loss: 0.5017 - val_accuracy: 0.8644 - val_auc: 0.4978 - val_loss: 0.4015\n",
      "Epoch 2/5\n",
      "\u001b[1m942/942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 478ms/step - accuracy: 0.8665 - auc: 0.5051 - loss: 0.4000 - val_accuracy: 0.8644 - val_auc: 0.4955 - val_loss: 0.3993\n",
      "Epoch 3/5\n",
      "\u001b[1m942/942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 485ms/step - accuracy: 0.8665 - auc: 0.5082 - loss: 0.3986 - val_accuracy: 0.8644 - val_auc: 0.5017 - val_loss: 0.4019\n",
      "Epoch 4/5\n",
      "\u001b[1m942/942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 496ms/step - accuracy: 0.8665 - auc: 0.5026 - loss: 0.3978 - val_accuracy: 0.8644 - val_auc: 0.5001 - val_loss: 0.3998\n",
      "Epoch 5/5\n",
      "\u001b[1m942/942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 486ms/step - accuracy: 0.8665 - auc: 0.5138 - loss: 0.3959 - val_accuracy: 0.8644 - val_auc: 0.4988 - val_loss: 0.3996\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 70ms/step - accuracy: 0.8619 - auc: 0.4897 - loss: 0.4049\n",
      "Validation Loss: 0.3996\n",
      "Validation Accuracy: 0.8644\n",
      "Validation AUC: 0.4988\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: combined_gen(train_img_flow, X_train_tab, y_train),\n",
    "    output_signature=(\n",
    "        (\n",
    "            tf.TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, X_train_tab.shape[1]), dtype=tf.float32)\n",
    "        ),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
    "    )\n",
    ")\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: combined_gen(val_img_flow, X_val_tab, y_val),\n",
    "    output_signature=(\n",
    "        (\n",
    "            tf.TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, X_val_tab.shape[1]), dtype=tf.float32)\n",
    "        ),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
    "    )\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=5,\n",
    "    steps_per_epoch=len(train_img_flow),\n",
    "    validation_steps=len(val_img_flow)\n",
    ")\n",
    "val_steps = len(val_img_flow)\n",
    "\n",
    "# Evaluate\n",
    "val_loss, val_accuracy, val_auc = model.evaluate(\n",
    "    combined_gen(val_img_flow, X_val_tab, y_val),\n",
    "    steps=val_steps\n",
    ")\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation AUC: {val_auc:.4f}\")\n",
    "\n",
    "# Save\n",
    "model.save('melanoma_model_multi_input.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f06970e",
   "metadata": {},
   "source": [
    "# Validation Accuracy : 86.44 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70d8298",
   "metadata": {
    "papermill": {
     "duration": 0.200856,
     "end_time": "2025-08-13T13:07:33.503503",
     "exception": false,
     "start_time": "2025-08-13T13:07:33.302647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d78c6f0",
   "metadata": {
    "papermill": {
     "duration": 0.19761,
     "end_time": "2025-08-13T13:07:33.900621",
     "exception": false,
     "start_time": "2025-08-13T13:07:33.703011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f734a741",
   "metadata": {
    "papermill": {
     "duration": 0.198023,
     "end_time": "2025-08-13T13:07:34.293230",
     "exception": false,
     "start_time": "2025-08-13T13:07:34.095207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 701123,
     "isSourceIdPinned": false,
     "sourceId": 1225697,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2584.208409,
   "end_time": "2025-08-13T13:07:37.852437",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-13T12:24:33.644028",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
